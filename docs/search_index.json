[
["index.html", "Fishery: Trade Module Welcome", " Fishery: Trade Module Luís G Silva e Silva and Christian Mongeau Statistician - ESSD - Methodological Innovation Team Welcome This document describes the main institutional actors involved in the migration as well as the FISHERIES TRADE resources (code lists, datasets, data tables) created to support the SWS plugins (R modules) to meet technical unit requirements. Furthermore, the modules are presented in the form of chapters providing a detailed description of their workflows involving input → processing → output as well as results showing whether the modules have lived up to expectations. IMPORTANT: Use the Chrome browser to have a correct vizualization of HTML outputs in this online document. "],
["migration-actors.html", "Migration actors", " Migration actors Any migration into the SWS requires the interaction between at least three actors: The technical unit interested in automating either some or all its analytical processes in the SWS. The technical unit can be treated as client demanding services from the counterparts responsible for the implementation of its data and statistical assets in the SWS. Therefore, a successful Fisheries Trade migration depends on the coordination between the technical division and other parts. In the Fisheries Trade - SWS migration framework the technical unit is called FIAS and is represented by: Stefania Vannuccini Senior Fishery Officer (FIAS) Adrienne Egger Fishery Officer (FIAS) Barbara Senfter Statistical clerk (FIAS) Thomas Berger Fishery Statistician (FIAS) The ESS - Methodological Innovation Team (ESS - SWS) responsible for the implementation and documentation of the required statistical processes. From the ESS - SWS team the focal points for Fishery Trade - SWS migration are: Carola Fabi Senior Statistician (ESSD) Luís Silva Statistician (ESSD) Christian Mongeau Statistician (ESSD) The CIO - SWS the primary backend and frontend maintainer of the SWS and responsible for the implementation and documentation of non-statistical processes (IT infrastructure). The CIO - SWS team have as interlocutors: Enrico Anello Full Stack Developer (CIO) Matteo Terrinoni Full Stack Developer (CIO) John Rowell Information Technology Officer (CIO) "],
["sec-intro.html", "1 Introduction", " 1 Introduction This document aims to describe the all data process involved in the Fisheries Trade module. "],
["sec-data.html", "2 Data 2.1 UNSD - COMTRADE 2.2 Eurostat 2.3 TDM and other sources 2.4 Data Builder", " 2 Data There are three main data sources for trade data involved in the Fishreries Trade module: UNSD, Eurostat, and TDM. The raw data are harvested by the Statistical Working System Team for both UNSD (Comtrade) and Eurostat by downloading through their API’s respectively, while the data from TDM database is provided by the FIAS. For less than ten countries, we get some information from other sources: FTR, national websites, etc. The frequency of harvesting the trade data needs to be agreed with ESS. There is an effort of the ESS and SWST to provide the user of the trade data a tool that enables users to harvest the data whenever they want. This tool and the process to harvest trade data is currently under development and aim to harvest only data from Comtrade and Eurostat. The other source should be define by FIAS unit. Currently, Comtrade and Eurostat data are stored in different data tables under the domain trade-input-data. The partner of data tables name that store the Comtrade data is “ct_tariffline_unlogged_YYYY”, where YYYY means the respective year, while for the Eurostat is “ce_combinednomenclature_unlogged_YYYY”. The TDM data is stored at data table “fishtrade_tdm_YYYY” under domain Fisheries Commodities. The other sources have the same standard name “fishtrade_other_sources_YYYY” under domain Fisheries Commodities. Altought, there are different data source, the data structure should have the same shape and columns. In Table 2.1 is shown the chapters that must be downloaded to cover all commodities for the Fisheries Trade Module. The chapters were defined and validated by the technical unit. Table 2.1: Chapters considered for Fisheries Trade module Code Description 03 Fish and crustaceans, molluscs and other aquatic invertebrates 05 Animal originated products; not elsewhere specified or included 12 Oil seeds and oleaginous fruits; miscellaneous grains, seeds and fruit, industrial or medicinal plants; straw and fodder 13 Lac; gums, resins and other vegetable saps and extracts 15 Animal or vegetable fats and oils and their cleavage products; prepared animal fats; animal or vegetable waxes 16 Meat, fish or crustaceans, molluscs or other aquatic invertebrates; preparations thereof 21 Miscellaneous edible preparations 23 Food industries, residues and wastes thereof; prepared animal fodder After filtering these chapters, some codes must be excluded, which are those codes that start by 030760 - Snails, Other Than Sea Snails, Live, Fresh, Chilled, Frozen, Dried, Salted Or In Brine or 160558 - Prepared Or Preserved Snails, Other Than Sea Snails. These codes are stored at data table fishtrade_param_hs_exclude under domain Fisheries Commodities. In Table 2.2, we go through the chapter by selecting the commodities which the code starts with the code shown in the table below. In this case, the filter is more specific than the previous one. Table 2.2: Codes considered for Fisheries Trade module Code Description 03 Fish and crustaceans, molluscs and other aquatic invertebrates 0508 Coral and similar materials, unworked or simply prepared, shells of molluscs, crustaceans or echinoderms and cuttle-bone, not cut to shape powder and waste thereof 0509 Sponges, natural; of animal origin 051191 Animal products; of fish or crustaceans, molluscs or other aquatic invertebrates; dead animals of chapter 03, unfit for human consumption 051199 Animal products; n.e.c. in chapter 5 121220 Seaweeds and other algae; of a kind used primarily for human consumption, fresh, chilled, frozen or dried, whether or not ground 130231 Mucilages and thickeners; agar-agar, whether or not modified, derived from vegetable products 1504 Fats and oils and their fractions of fish or marine mammals; whether or not refined, but not chemically modified 1604 Prepared or preserved fish; caviar and caviar substitutes prepared from fish eggs 1605 Crustaceans, molluscs and other aquatic invertebrates, prepared or preserved 210390 Sauces and preparations therefor; mixed condiments and mixed seasonings 230120 Flours, meals and pellets; of fish or of crustaceans, molluscs or other aquatic invertebrates 230990 Dog or cat food; (not put up for retail sale), used in animal feeding 2.1 UNSD - COMTRADE The tariff line data from UNSD contains multiple rows with identical combination of reporter/partner/commodity/flow/year/qunit (unit of quantity). Those are transactions registered separately, thus rows containinig non-missing values and quantities can be aggregated. Missing variables of the same type are also aggregated if they are all missing, as they will produce a missing aggregated value for missing disaggregated values while correctly summing the remaining variables. Commodities at Tariff Line level, i.e., at the national code level. The code is composed by at least six digits up to twelve, where the first six digits follow the Harmonized System, and the other digits are country-specific. The Harmonized System is an international nomenclature for the classification of products. It allows participating countries to classify traded goods on a common basis for customs purposes. At the international level, the Harmonized System (HS) for classifying goods is a six-digit code system. — Harmonized System UNSD Tariff line data reports area code with Tariff line M49 standard (which are different for official M49). The area code is converted in FAO country code using a specific conversion table provided by Team ENV. Countries that are not supposed to exist in the year for which the module runs are removed from the data (e.g., Serbia did not exist as a single country in 2004). European countries (as reporters) already in Eurostat data are removed. Area codes not mapping to any FAO country code are separately saved and removed from further analyses. All countries mapping to code 252 (which correponds to undefined areas) are mapped to the 896 M49 code (“Other nei”). The flow codes of re-Import (code 4) are recoded into Import (code 1) and codes of re-Export (code 3) are kept. This procedure is applied following UNSD standards: Exports of a country can be distinguished as exports of domestic goods and exports of foreign goods. The second class is generally referred to as re-exports. The exports shown in our database contain both the exports of domestic and foreign goods. Re-exports are exports of foreign goods in the same state as previously imported; they are to be included in the country exports. It is recommended that they be recorded separately for analytical purposes. This may require the use of supplementary sources of information in order to determine the origin of re-exports, i.e., to determine that the goods in question are indeed re-exports rather than the export of goods that have acquired domestic origin through processing. Re-imports are goods imported in the same state as previously exported. They are included in the country imports. It is recommended that they be recorded separately for analytical purposes. This may require the use of supplementary sources of information in order to determine the origin of re-imports, i.e., to determine that the goods in question are indeed re-imports rather than the import of goods that have acquired foreign origin through processing. There are several reasons why an exported good might return to the country of origin. The exported good might be defective, the importer might have defaulted on payments or cancelled the order, the authorities might have imposed an import barrier, or demand or prices in the country of origin might have made it worthwhile to bring the good back. — See http://unstats.un.org/unsd/tradekb/Knowledgebase/Reexports-and-Reimports 2.2 Eurostat Only numeric codes of reporters and partners are kept (letters are not allowed; basically this removes the “EU” total). Only numeric CN8 codes (hs) are kept (letters are not allowed). Only stat_regime equal to 4 is kept. In this system [“Statistical regime 4” or “Total trade”], the recorded aggregates include all goods entering or leaving the economic territory of a country with the exception of simple transit trade. In particular, all goods received into customs warehouses are recorded as imports, regardless of whether they subsequently go into free circulation in the Member State of receipt. Similarly, outgoing goods from customs warehouses are included in the general trade aggregates, at the time they leave the Member State. — See pag. 10 in DG Trade Statistical Guide, July 2019, https://trade.ec.europa.eu/doclib/docs/2013/may/tradoc_151348.pdf 2.3 TDM and other sources The TDM and other sources are processed using the same function that processing the data from Comtrade. Some small adaption should be done to fit well the data from these different data sources. 2.4 Data Builder The Data Builder is a module developed to build the data by choosing the country, year, and data source for each flow (import, export). For example, the user can select the year 2019, Brazil, and TDM for both sources. Given this selection, the data builder will get the raw data from the specific data sources and then process it. The process is composed basically by, renaming columns, filtering chapter, converting M49 codes, and recode variables. After to process the raw data the Data Builder store them in the SWS as the data table fishtrade_built_data under domain “Fisheries Commodities”. In Figure 2.1, we show the data build workflow. The user must select the country, year, and data source, and then the module will save the data built into SWS for being used for the next processes. Figure 2.1: Data builder data flow. "],
["sec-mapping.html", "3 Mapping trade data", " 3 Mapping trade data TODO "],
["sec-missing.html", "4 Missing data and imputation", " 4 Missing data and imputation TODO "],
["outlier-detection.html", "5 Outlier Detection 5.1 Data 5.2 Outlier detection in the aggregated level 5.3 Correction of main outlier", " 5 Outlier Detection 5.1 Data The outlier detection methods are applied in the unit value (uv) variable, which is the ratio between the monetary transaction value and its weight. In this first step of this procedure, we attempt to figure out outliers in the aggregate level, and then we try to fix the transactions (disaggregated level) that were responsible for generating the outliers detected. The aggregated level means to compute the unit value by reporter, flow, and FAO code, i.e., for each combination of reporter, flow, and FAO code we calculate the ratio between the summing of the monetary value and the summing of the weight. For instance, in Table 1 is shown a subset from the full data using the following parameters: reporter: 76 year: 2005 flow: 1 faocode: 292.9.1.90 To calculate the unit value in the aggregate level, it is needed to apply the equation below: \\[uv = \\frac{\\sum_{p = 1}^{P} value_p}{\\sum_{p = 1}^{P} weight_p}\\] where \\(value_p\\) is the monetary value from the p-th partner, as well as \\(weight_p\\) is the transaction weight, \\(P\\) is the total of partners in this given combination, in this small example \\(P = 12\\). In order to make this report comprehensible, we show the uv calculation step-by-step as following: \\[\\begin{align} uv &amp; = \\frac{65438+1910 + \\cdots + 44329+438234}{73173+613 + \\cdots + 5949+93719} \\\\ \\\\ &amp; = \\frac{1,893,528}{1,805,531} \\\\ \\\\ &amp; = 1.05 \\end{align}\\] If we repeat it procedure for all available year for this combination, we will find the values shown in Table 2. The highlighted row shows the uv computed previously, as shown in the equations sequence. In Figure 1 is shown the same information stored in Table 1, i.e., the unit value computed in the aggregated level by year. The outlier can be easily identified when we look to the graphic below. The uv seems to be a stable behavior from 2000 to 2011 when you analyze Figure 1. However, in 2012 a sharp increase in the uv is noted. On the other hand, when we look at Figure 2, that is the same information, but without the year 2012, so it is possible to see clearly the increasing trend starting in 2007. Figure 5.1: Figure 1: The whole time series of imports. Figure 5.2: Figure 2: The time series of imports without the year 2012. Despite the visual approach works well to identify the possible outliers, it is not possible to check each graphic to figure out the outliers. Therefore, it needs to use a general rule that can be applied in each combination. In the next section, we show two methods to figure out outliers in the trade data, the first one is the Boxplot, and the second one is the Median Absolute Deviation (MAD). 5.2 Outlier detection in the aggregated level TODO 5.2.1 Boxplot One of the methods to try figured out outlier in the aggregated data is the boxplot rule. Set the coefficient \\(k\\), for instance \\(k = 5\\). Compute the percentiles: 25% (\\(Q_1\\)), and 75% (\\(Q_3\\)). Compute the interquartile range (IQR): \\(IQR = Q_3 - Q_1\\) Compute \\(\\text{limsup} = Q_3 + k \\times IQR\\) Compute \\(\\text{liminf} = Q_1 - k \\times IQR\\) If \\(uv &gt; \\text{limsup} \\mid uv &lt; \\text{liminf}\\), then \\(uv\\) is a outlier. The IQR is a measure of variability, based on dividing a data set into quartiles. Quartiles divide a rank-ordered data set into four equal parts. The values that separate parts are called the first, second, and third quartiles; and they are denoted by Q1, Q2, and Q3, respectively. 5.2.1.1 Example \\(k = 5\\) Compute the percentiles: \\(Q_1 = 1.167\\) \\(Q_3 = 1.788\\) \\(IQR = Q_3 - Q_1 = 0.621\\) \\(\\text{limsup} = 4.893\\) \\(\\text{liminf} = -1.938\\) Figure 5.3: Figure 3: Boxplot exemplifying the outlier detection. 5.2.2 Median Absolute Deviation (MAD) There are many methods for outlier detection, for instance, model-based, quantiles methods, and deviation from average. However, in this task, we are manipulating the massive amount of heterogeneous data grouped in country and commodity class. Therefore, a general and straightforward method can be an excellent choice to perform outlier detection. Given this scenario, the Median Absolute Deviation (MAD) was adopted and applied for each commodity per year. The main idea of this strategy is to find outliers that are away from its median when compared in the same commodity. \\[ z = \\frac{|uv_i - median(uv_i)|}{MAD} \\\\ MAD = median(|uv_i - median(uv_i)|) \\] The steps are as follow: Compute \\(z\\) as shown in the equation above. Compute \\(\\text{limsup} = median(z) + k \\times 1.4826 \\times MAD\\) Compute \\(\\text{liminf} = median(z) - k \\times 1.4826 \\times MAD\\) If \\(z &gt; \\text{limsup} \\mid z &lt; \\text{liminf}\\), then \\(uv\\) is a outlier. 5.2.2.1 Example Compute \\(z\\) as shown in the equation above. Compute \\(\\text{limsup} = 1.22 + 5 \\times 1.4826 \\times 0.25 = 3.07\\) Compute \\(\\text{liminf} = 1.22 - 5 \\times 1.4826 \\times 0.25 = -0.63\\) If \\(z &gt; \\text{limsup} \\mid z &lt; \\text{liminf}\\), then \\(uv\\) is a outlier. Figure 5.4: Figure 4: Outliers detected by the MAD method.. 5.3 Correction of main outlier Once the outlier is detected at the aggregated level, the following step is to figure out the transaction values that were responsible for contributing to the outlier. In this project, we use two approaches for attempting to fix the discrepant values detected in the previous step. The first one is a model-based, and the second one is based on the median weighted average. The choice of approach is based on the number of transactions available on the disaggregated level. If the number of transaction is less than \\(5\\), then we choose the model-based approach, otherwise the median weighted average is chosen. For instance, in the previous step, the year 2012 was detected as an outlier by the two approaches. When this year is disgregated, there is only one (\\(n = 1\\)) transaction that could be responsible for generating this outlier. In this case, the approach chosen is the model-based, once \\(n = 1\\). 5.3.1 Locally Estimated Scatterplot Smoothing (LOESS) To fix the transactions that generated the outlier in the aggregated level is fitted a LOESS model considering the log(uv) as variable response and year as the covariate. The rows which the year was detected as outlier were removed before to fit the model. Once the model is fitted, it is used to predict a new value to the given year. In our example, the year is 2012 and the value predicted by model is 4.701. 5.3.1.1 Example Figure 5.5: Figure 4: Correction of the outlier using the LOESS model. 5.3.2 Median weighted average When the number of transactions in the disaggregated level is greater than or equal \\(5\\), i.e., \\(n \\geq 5\\), the method Median weighted is chosen. In this case, before to apply the correction method we should to identify those/that transactions responsible for generating the outlier. Therefore, the methods to detect outlier mentioned previously are applied in the disaggregated level and then it is possible to identify that/those discrepant transactions. Once the discrepant transactions are identified the correction is value is computed as following: The historical median for uv for each partner is calculated - \\(M_{hist}\\). The median for uv for the given year is calculated - \\(M_{partner}\\) The new uv is \\(uv_{new} = \\frac{M_{hist} + M_{partner}}{2}\\) "],
["sec-mirroring.html", "6 Trade partners", " 6 Trade partners TODO "]
]
