[
["index.html", "Fishery: Trade Module Welcome", " Fishery: Trade Module Lu√≠s G. Silva e Silva Statistician - ESSD - Methodological Innovation Team Welcome "],
["sec-intro.html", "Chapter 1 Introduction", " Chapter 1 Introduction TODO "],
["sec-workflow.html", "Chapter 2 Trade data Workflow 2.1 Get started data", " Chapter 2 Trade data Workflow In this section, we show the fisheries trade workflow passing by the mapping commodities, outlier detection, and correction of the main outliers. The idea is show the methodology applied in each step using a small example. 2.1 Get started data we selected the country Brazil to show the R module steps. First we get the data from Tariff Line source, and filter only the valid commodities. In this case, we remove the commodities that HS code start with 0301. This removing rule was determined by the fishery team. no_imputation &lt;- &quot;0301&quot;; REPORTER &lt;- &quot;76&quot; get_working_data(.reporter = REPORTER, .local = TRUE) tldata &lt;- tldata[substr(hs, 1, 4) != no_imputation] head(tldata) ## year reporter partner flow hs hsrep value weight qty ## 1: 2000 76 56 2 030629000000 H1 399 NA NA ## 2: 2000 76 32 1 210390110000 H1 268359 197636 197636 ## 3: 2000 76 32 1 210390110000 H1 310331 228406 228406 ## 4: 2000 76 32 1 210390110000 H1 104457 83355 83355 ## 5: 2000 76 32 1 210390110000 H1 294883 247896 247896 ## 6: 2000 76 32 1 210390110000 H1 244719 210526 210526 ## qunit hslength src ## 1: 1 8 unsd ## 2: 8 8 unsd ## 3: 8 8 unsd ## 4: 8 8 unsd ## 5: 8 8 unsd ## 6: 8 8 unsd There are many methods for outlier detection, for instance, model-based, quantiles methods, and deviation from average. However, in this task, we are manipulating the massive amount of heterogeneous data grouped in country and commodity class. Therefore, a general and straightforward method can be an excellent choice to perform outlier detection. Given this scenario, the Median Absolute Deviation (MAD) was adopted and applied for each commodity per year. The main idea of this strategy is to find outliers that are away from its median when compared in the same commodity. "],
["outlier-detection.html", "Chapter 3 Outlier Detection 3.1 Data 3.2 Outlier detection in the aggregated level 3.3 Correction of main outlier", " Chapter 3 Outlier Detection 3.1 Data The outlier detection methods are applied in the unit value (uv) variable, which is the ratio between the monetary transaction value and its weight. In this first step of this procedure, we attempt to figure out outliers in the aggregate level, and then we try to fix the transactions (disaggregated level) that were responsible for generating the outliers detected. The aggregated level means to compute the unit value by reporter, flow, and FAO code, i.e., for each combination of reporter, flow, and FAO code we calculate the ratio between the summing of the monetary value and the summing of the weight. For instance, in Table 1 is shown a subset from the full data using the following parameters: reporter: 76 year: 2005 flow: 1 faocode: 292.9.1.90 To calculate the unit value in the aggregate level, it is needed to apply the equation below: \\[uv = \\frac{\\sum_{p = 1}^{P} value_p}{\\sum_{p = 1}^{P} weight_p}\\] where \\(value_p\\) is the monetary value from the p-th partner, as well as \\(weight_p\\) is the transaction weight, \\(P\\) is the total of partners in this given combination, in this small example \\(P = 12\\). In order to make this report comprehensible, we show the uv calculation step-by-step as following: \\[\\begin{align} uv &amp; = \\frac{65438+1910 + \\cdots + 44329+438234}{73173+613 + \\cdots + 5949+93719} \\\\ \\\\ &amp; = \\frac{1,893,528}{1,805,531} \\\\ \\\\ &amp; = 1.05 \\end{align}\\] If we repeat it procedure for all available year for this combination, we will find the values shown in Table 2. The highlighted row shows the uv computed previously, as shown in the equations sequence. In Figure 1 is shown the same information stored in Table 1, i.e., the unit value computed in the aggregated level by year. The outlier can be easily identified when we look to the graphic below. The uv seems to be a stable behavior from 2000 to 2011 when you analyze Figure 1. However, in 2012 a sharp increase in the uv is noted. On the other hand, when we look at Figure 2, that is the same information, but without the year 2012, so it is possible to see clearly the increasing trend starting in 2007. Figure 3.1: Figure 1: The whole time series of imports. Figure 3.2: Figure 2: The time series of imports without the year 2012. Despite the visual approach works well to identify the possible outliers, it is not possible to check each graphic to figure out the outliers. Therefore, it needs to use a general rule that can be applied in each combination. In the next section, we show two methods to figure out outliers in the trade data, the first one is the Boxplot, and the second one is the Median Absolute Deviation (MAD). 3.2 Outlier detection in the aggregated level TODO 3.2.1 Boxplot One of the methods to try figured out outlier in the aggregated data is the boxplot rule. Set the coefficient \\(k\\), for instance \\(k = 5\\). Compute the percentiles: 25% (\\(Q_1\\)), and 75% (\\(Q_3\\)). Compute the interquartile range (IQR): \\(IQR = Q_3 - Q_1\\) Compute \\(\\text{limsup} = Q_3 + k \\times IQR\\) Compute \\(\\text{liminf} = Q_1 - k \\times IQR\\) If \\(uv &gt; \\text{limsup} \\mid uv &lt; \\text{liminf}\\), then \\(uv\\) is a outlier. The IQR is a measure of variability, based on dividing a data set into quartiles. Quartiles divide a rank-ordered data set into four equal parts. The values that separate parts are called the first, second, and third quartiles; and they are denoted by Q1, Q2, and Q3, respectively. 3.2.1.1 Example \\(k = 5\\) Compute the percentiles: \\(Q_1 = 1.167\\) \\(Q_3 = 1.788\\) \\(IQR = Q_3 - Q_1 = 0.621\\) \\(\\text{limsup} = 4.893\\) \\(\\text{liminf} = -1.938\\) Figure 3.3: Figure 3: Boxplot exemplifying the outlier detection. 3.2.2 Median Absolute Deviation (MAD) There are many methods for outlier detection, for instance, model-based, quantiles methods, and deviation from average. However, in this task, we are manipulating the massive amount of heterogeneous data grouped in country and commodity class. Therefore, a general and straightforward method can be an excellent choice to perform outlier detection. Given this scenario, the Median Absolute Deviation (MAD) was adopted and applied for each commodity per year. The main idea of this strategy is to find outliers that are away from its median when compared in the same commodity. \\[ z = \\frac{|uv_i - median(uv_i)|}{MAD} \\\\ MAD = median(|uv_i - median(uv_i)|) \\] The steps are as follow: Compute \\(z\\) as shown in the equation above. Compute \\(\\text{limsup} = median(z) + k \\times 1.4826 \\times MAD\\) Compute \\(\\text{liminf} = median(z) - k \\times 1.4826 \\times MAD\\) If \\(z &gt; \\text{limsup} \\mid z &lt; \\text{liminf}\\), then \\(uv\\) is a outlier. 3.2.2.1 Example Compute \\(z\\) as shown in the equation above. Compute \\(\\text{limsup} = 1.22 + 5 \\times 1.4826 \\times 0.25 = 3.07\\) Compute \\(\\text{liminf} = 1.22 - 5 \\times 1.4826 \\times 0.25 = -0.63\\) If \\(z &gt; \\text{limsup} \\mid z &lt; \\text{liminf}\\), then \\(uv\\) is a outlier. Figure 3.4: Figure 4: Outliers detected by the MAD method.. 3.3 Correction of main outlier Once the outlier is detected at the aggregated level, the following step is to figure out the transaction values that were responsible for contributing to the outlier. In this project, we use two approaches for attempting to fix the discrepant values detected in the previous step. The first one is a model-based, and the second one is based on the median weighted average. The choice of approach is based on the number of transactions available on the disaggregated level. If the number of transaction is less than \\(5\\), then we choose the model-based approach, otherwise the median weighted average is chosen. For instance, in the previous step, the year 2012 was detected as an outlier by the two approaches. When this year is disgregated, there is only one (\\(n = 1\\)) transaction that could be responsible for generating this outlier. In this case, the approach chosen is the model-based, once \\(n = 1\\). 3.3.1 Locally Estimated Scatterplot Smoothing (LOESS) To fix the transactions that generated the outlier in the aggregated level is fitted a LOESS model considering the log(uv) as variable response and year as the covariate. The rows which the year was detected as outlier were removed before to fit the model. Once the model is fitted, it is used to predict a new value to the given year. In our example, the year is 2012 and the value predicted by model is 4.701. 3.3.1.1 Example Figure 3.5: Figure 4: Correction of the outlier using the LOESS model. 3.3.2 Median weighted average When the number of transactions in the disaggregated level is greater than or equal \\(5\\), i.e., \\(n \\geq 5\\), the method Median weighted is chosen. In this case, before to apply the correction method we should to identify those/that transactions responsible for generating the outlier. Therefore, the methods to detect outlier mentioned previously are applied in the disaggregated level and then it is possible to identify that/those discrepant transactions. Once the discrepant transactions are identified the correction is value is computed as following: The historical median for uv for each partner is calculated - \\(M_{hist}\\). The median for uv for the given year is calculated - \\(M_{partner}\\) The new uv is \\(uv_{new} = \\frac{M_{hist} + M_{partner}}{2}\\) "]
]
